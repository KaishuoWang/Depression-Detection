{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uQVRaq3t5Ve",
    "outputId": "7e67ff6a-12da-41e2-bc75-71af773cce9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: transformers in /root/miniconda3/lib/python3.8/site-packages (4.35.0)\n",
      "Requirement already satisfied: evaluate in /root/miniconda3/lib/python3.8/site-packages (0.4.1)\n",
      "Requirement already satisfied: accelerate in /root/miniconda3/lib/python3.8/site-packages (0.24.1)\n",
      "Requirement already satisfied: sentencepiece in /root/miniconda3/lib/python3.8/site-packages (0.1.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from transformers) (3.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: multiprocess in /root/miniconda3/lib/python3.8/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/lib/python3.8/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: dill in /root/miniconda3/lib/python3.8/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.8/site-packages (from evaluate) (2.0.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from evaluate) (2.14.5)\n",
      "Requirement already satisfied: responses<0.19 in /root/miniconda3/lib/python3.8/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /root/miniconda3/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (13.0.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.8/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /root/miniconda3/lib/python3.8/site-packages (from accelerate) (2.0.0+cu118)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: lit in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (15.0.7)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.26.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.8/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers evaluate accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vlsue_9ut_Mp",
    "outputId": "e5c25d09-539e-47ff-bdfd-421feb02a1fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    train_path = '/content/gdrive/MyDrive/advanced-ml-project/data/train.tsv'\n",
    "    test_path = '/content/gdrive/MyDrive/advanced-ml-project/data/test.tsv'\n",
    "    dev_path = '/content/gdrive/MyDrive/advanced-ml-project/data/dev.tsv'\n",
    "\n",
    "    eval_model_path = '/content/gdrive/MyDrive/advanced-ml-project/masked_lm_model.pth'\n",
    "except:\n",
    "    train_path = 'data/train.tsv'\n",
    "    test_path = 'data/test.tsv'\n",
    "    dev_path = 'data/dev.tsv'\n",
    "\n",
    "    eval_model_path = 'masked_lm_model.pth'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJceSXvYw0nh"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "rlPeTWzCw0TO",
    "outputId": "16f66c53-6078-496c-d9a4-4c89d6407607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train: 8891\n",
      "Length of test: 3245\n",
      "Length of dev: 4496\n",
      "label\n",
      "moderate    6019\n",
      "healthy     1971\n",
      "severe       901\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_pid_2550</td>\n",
       "      <td>Now that 2019 is behind us, and we greet 2020....</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_pid_8552</td>\n",
       "      <td>Is anyone awake? : Please help, I need a voice...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_pid_744</td>\n",
       "      <td>being alive is fucking exhausting : [removed]</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_pid_2902</td>\n",
       "      <td>I came to the conclusion that I'm dead inside....</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_pid_640</td>\n",
       "      <td>Happy new year : Fuck 2019...2020 will be bett...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_pid_8543</td>\n",
       "      <td>I don’t want to live my life sick and tired : ...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_pid_228</td>\n",
       "      <td>Had probably the worst year in my life.. : 201...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_pid_6633</td>\n",
       "      <td>Insecurities, fuck em. : I constantly feel lik...</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_pid_1805</td>\n",
       "      <td>Fuck Holidays : I feel the loneliest around th...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_pid_6101</td>\n",
       "      <td>Goodbye 2019. May you rot in hell. :</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PID                                               text     label\n",
       "0  train_pid_2550  Now that 2019 is behind us, and we greet 2020....  moderate\n",
       "1  train_pid_8552  Is anyone awake? : Please help, I need a voice...    severe\n",
       "2   train_pid_744      being alive is fucking exhausting : [removed]  moderate\n",
       "3  train_pid_2902  I came to the conclusion that I'm dead inside....  moderate\n",
       "4   train_pid_640  Happy new year : Fuck 2019...2020 will be bett...  moderate\n",
       "5  train_pid_8543  I don’t want to live my life sick and tired : ...    severe\n",
       "6   train_pid_228  Had probably the worst year in my life.. : 201...  moderate\n",
       "7  train_pid_6633  Insecurities, fuck em. : I constantly feel lik...   healthy\n",
       "8  train_pid_1805  Fuck Holidays : I feel the loneliest around th...  moderate\n",
       "9  train_pid_6101              Goodbye 2019. May you rot in hell. :    healthy"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(train_path, sep='\\t', header=0)\n",
    "train['label'] = train['label'].apply(lambda x: 'healthy' if x == 'not depression' else x)\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "print('Length of train:', len(train))\n",
    "\n",
    "test = pd.read_csv(test_path, sep='\\t', header=0)\n",
    "test['label'] = test['label'].apply(lambda x: 'healthy' if x == 'not depression' else x)\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "print('Length of test:', len(test))\n",
    "\n",
    "dev = pd.read_csv(dev_path, sep='\\t', header=0)\n",
    "dev['label'] = dev['label'].apply(lambda x: 'healthy' if x == 'not depression' else x)\n",
    "dev = dev.sample(frac=1).reset_index(drop=True)\n",
    "print('Length of dev:', len(dev))\n",
    "\n",
    "print(train.label.value_counts())\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PB3kC3ZXzNji"
   },
   "source": [
    "We add the prompt to the begining of the sentence, so that when the sequence is longer than the max sequence length of the model, we can always keep our prompt and mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yCeb_cjvxRrY"
   },
   "outputs": [],
   "source": [
    "label2idx = {'healthy': 0, 'severe': 1, 'moderate': 2}\n",
    "\n",
    "class MLMDataset(Dataset):\n",
    "    def __init__(self, X, y, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        prompt = \"The level of depression in the following tweet is {}.\\n{}\"\n",
    "        text = prompt.format(self.tokenizer.mask_token, self.X[idx])\n",
    "        inputs = self.tokenizer(text, padding='max_length', max_length=512, return_tensors='pt', truncation=True)\n",
    "\n",
    "        mask_index = torch.where(inputs['input_ids'].squeeze() == tokenizer.mask_token_id)[0]\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label2idx[self.y[idx]]),\n",
    "            'mask_index': mask_index\n",
    "        }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large/\")\n",
    "\n",
    "train_data = MLMDataset(train.text, train.label, tokenizer)\n",
    "test_data = MLMDataset(test.text, test.label, tokenizer)\n",
    "dev_data = MLMDataset(dev.text, dev.label, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=True)\n",
    "dev_loader = DataLoader(dev_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8x2JRZd39HR"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qZDm3ouqiupG"
   },
   "outputs": [],
   "source": [
    "class MaskedLMModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(MaskedLMModel, self).__init__()\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "        \n",
    "        # classification head\n",
    "        self.dense = nn.Linear(self.model.config.vocab_size, 1024)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_proj = nn.Linear(1024, 3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, mask_index):\n",
    "        outputs = self.model(input_ids, attention_mask)\n",
    "        \n",
    "        # classification head\n",
    "        outputs = outputs[0][[batch for batch in range(len(mask_index))], mask_index, :] # [:, 0, :]\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.dense(outputs)\n",
    "        outputs = torch.tanh(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.out_proj(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwQK2agazhWj"
   },
   "source": [
    "We use weighted loss here in order to deal with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "W_KNJwhU3Q72"
   },
   "outputs": [],
   "source": [
    "def compute_class_weight(train_y):\n",
    "    \"\"\"\n",
    "    Compute class weight given imbalanced training data\n",
    "    Usually used in the neural network model to augment the loss function (weighted loss function)\n",
    "    Favouring/giving more weights to the rare classes.\n",
    "    \"\"\"\n",
    "    import sklearn.utils.class_weight as scikit_class_weight\n",
    "\n",
    "    train_y = [label2idx[each] for each in train_y]\n",
    "    class_list = list(set(train_y))\n",
    "    class_weight_value = scikit_class_weight.compute_class_weight(class_weight='balanced', classes=class_list, y=train_y)\n",
    "\n",
    "    return torch.tensor(class_weight_value, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "y6fugZ0d4ENj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = AutoModelForMaskedLM.from_pretrained(\"roberta-large\").to(device)\n",
    "model = MaskedLMModel(\"roberta-large/\").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "loss_func = nn.CrossEntropyLoss(compute_class_weight(train.label.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "af6bd4c4021f464bbbd58e9744256b7e",
      "d27c83af8506476eaf00281f2fab6991",
      "d8bd250c41e94e7e8363ed28c0e742e0",
      "1cd0b9fde8e44553b354ba5ab1fde946",
      "5abf33fc3f23444c8fdbdc581fffbab4",
      "dbcd55d53d2f4ff7babe32283d13c008",
      "770e1a9554444f1c86bd98e0bf73aa23",
      "7ed13f139ee645089ab2d2a0b09f7ee3",
      "ce6bd597c98b4d339b669b17210bf8c7",
      "21c817ad7a1a4dbdad610e0964f151bd",
      "297a825c2f4f4d9f94a3191533552fb3",
      "d21aefea2bec4ae5893b37fff434768d",
      "ce27a62420cc4316b7cdeebc88347f5b",
      "ced02903d73e4694bc552a945dcf51c0",
      "03f6e0116652403083d876f1ad72b07f",
      "076a12d2cace462d9003839f0b07944f",
      "dbab8303ce4640e9aadb192fcafd5607",
      "04bbf20e12bd4773ae0c3422f50d822e",
      "4a97ed13e4044eb58a22a320ec0919a0",
      "fb53bccc684c4e9eb44877e8e6b5f9bc",
      "690626d403034b7ba7e69a201c189ff1",
      "9ce6f3218cff4585bbf014e89bdc489d"
     ]
    },
    "id": "QO3qhUkm5r9A",
    "outputId": "5431fb2a-c247-406b-ba45-7a63af4f4298"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c47f27e7034e17afe1956191fa0f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Process:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/406 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 1.1727, Training f1: 0.5009, Testing Loss: 1.0742, Testing f1: 0.5484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/406 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training Loss: 1.1066, Training f1: 0.4904, Testing Loss: 1.0946, Testing f1: 0.5479\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22924b67a1a4808a7051ac8d3dd8d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# print(outputs.shape)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#         selected_output = outputs[[batch for batch in range(labels.shape[0])], mask_index, :]\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, labels)\n\u001b[0;32m---> 24\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m         y_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 5\n",
    "best_testing_loss = float(\"inf\")\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in tqdm(range(num_epoch), desc='Training Process'):\n",
    "    training_losses, training_f1 = [], []\n",
    "    testing_losses, testing_f1 = [], []\n",
    "\n",
    "    model.train()\n",
    "    for _, inputs in enumerate(tqdm(train_loader, leave=False, desc=f\"Epoch {epoch + 1}/{num_epoch}\")):\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        labels = inputs['labels'].to(device)\n",
    "        mask_index = inputs['mask_index'].to(device).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask, mask_index)\n",
    "        # print(outputs.shape)\n",
    "#         selected_output = outputs[[batch for batch in range(labels.shape[0])], mask_index, :]\n",
    "\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_preds = torch.argmax(outputs, 1)\n",
    "        f1 = f1_score(labels.cpu(), y_preds.cpu(), average='weighted')\n",
    "\n",
    "        training_losses.append(loss.item())\n",
    "        training_f1.append(f1)\n",
    "\n",
    "    model.eval()\n",
    "    for _, inputs in enumerate(tqdm(test_loader, leave=False, desc=\"Evaluating\")):\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        labels = inputs['labels'].to(device)\n",
    "        mask_index = inputs['mask_index'].to(device).squeeze()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask, mask_index)\n",
    "        # selected_output = outputs[[batch for batch in range(labels.shape[0])], mask_index, :]\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        y_preds = torch.argmax(outputs, 1)\n",
    "        f1 = f1_score(labels.cpu(), y_preds.cpu(), average='weighted')\n",
    "        \n",
    "        testing_losses.append(loss.item())\n",
    "        testing_f1.append(f1)\n",
    "    \n",
    "    if np.mean(testing_losses) < best_testing_loss:\n",
    "        best_testing_loss = np.mean(testing_losses)\n",
    "        best_model_state = model.state_dict()\n",
    "        \n",
    "    print('Epoch %d: Training Loss: %.4f, Training f1: %.4f, Testing Loss: %.4f, Testing f1: %.4f' % \n",
    "          (epoch + 1, np.mean(training_losses), np.mean(training_f1), np.mean(testing_losses), np.mean(testing_f1)))\n",
    "\n",
    "print('Best testing loss is', best_testing_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if best_model_state is not None:\n",
    "    torch.save(best_model_state, eval_model_path)\n",
    "# torch.save(model.state_dict(), eval_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZcuTshNX7xX"
   },
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MaskedLMModel('roberta-large/').to(device)\n",
    "model.load_state_dict(torch.load(eval_model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5L9j8P85YDVr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_losses = []\n",
    "testing_f1 = []\n",
    "model.eval()\n",
    "for _, inputs in enumerate(tqdm(dev_loader, leave=False, desc=\"Evaluating\")):\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    labels = inputs['labels'].to(device)\n",
    "    mask_index = inputs['mask_index'].to(device).squeeze()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "    selected_output = outputs[[batch for batch in range(labels.shape[0])], mask_index, :]\n",
    "    loss = loss_func(selected_output, labels)\n",
    "    \n",
    "    y_preds = torch.argmax(selected_output, 1)\n",
    "    f1 = f1_score(labels.cpu(), y_preds.cpu(), average='weighted')\n",
    "    \n",
    "    testing_losses.append(loss.item())\n",
    "    testing_f1.append(f1)\n",
    "\n",
    "print('Evaluation loss: %.4f, Evaluation f1-score: %.4f' % (np.mean(testing_losses), np.mean(testing_f1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbCTFhV7gcho"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03f6e0116652403083d876f1ad72b07f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_690626d403034b7ba7e69a201c189ff1",
      "placeholder": "​",
      "style": "IPY_MODEL_9ce6f3218cff4585bbf014e89bdc489d",
      "value": " 151/4446 [01:48&lt;53:32,  1.34it/s]"
     }
    },
    "04bbf20e12bd4773ae0c3422f50d822e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "076a12d2cace462d9003839f0b07944f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cd0b9fde8e44553b354ba5ab1fde946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21c817ad7a1a4dbdad610e0964f151bd",
      "placeholder": "​",
      "style": "IPY_MODEL_297a825c2f4f4d9f94a3191533552fb3",
      "value": " 0/3 [00:00&lt;?, ?it/s]"
     }
    },
    "21c817ad7a1a4dbdad610e0964f151bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "297a825c2f4f4d9f94a3191533552fb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4a97ed13e4044eb58a22a320ec0919a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5abf33fc3f23444c8fdbdc581fffbab4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "690626d403034b7ba7e69a201c189ff1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "770e1a9554444f1c86bd98e0bf73aa23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ed13f139ee645089ab2d2a0b09f7ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ce6f3218cff4585bbf014e89bdc489d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af6bd4c4021f464bbbd58e9744256b7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d27c83af8506476eaf00281f2fab6991",
       "IPY_MODEL_d8bd250c41e94e7e8363ed28c0e742e0",
       "IPY_MODEL_1cd0b9fde8e44553b354ba5ab1fde946"
      ],
      "layout": "IPY_MODEL_5abf33fc3f23444c8fdbdc581fffbab4"
     }
    },
    "ce27a62420cc4316b7cdeebc88347f5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbab8303ce4640e9aadb192fcafd5607",
      "placeholder": "​",
      "style": "IPY_MODEL_04bbf20e12bd4773ae0c3422f50d822e",
      "value": "Epoch 1/3:   3%"
     }
    },
    "ce6bd597c98b4d339b669b17210bf8c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ced02903d73e4694bc552a945dcf51c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a97ed13e4044eb58a22a320ec0919a0",
      "max": 4446,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb53bccc684c4e9eb44877e8e6b5f9bc",
      "value": 151
     }
    },
    "d21aefea2bec4ae5893b37fff434768d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce27a62420cc4316b7cdeebc88347f5b",
       "IPY_MODEL_ced02903d73e4694bc552a945dcf51c0",
       "IPY_MODEL_03f6e0116652403083d876f1ad72b07f"
      ],
      "layout": "IPY_MODEL_076a12d2cace462d9003839f0b07944f"
     }
    },
    "d27c83af8506476eaf00281f2fab6991": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbcd55d53d2f4ff7babe32283d13c008",
      "placeholder": "​",
      "style": "IPY_MODEL_770e1a9554444f1c86bd98e0bf73aa23",
      "value": "Training Process:   0%"
     }
    },
    "d8bd250c41e94e7e8363ed28c0e742e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ed13f139ee645089ab2d2a0b09f7ee3",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce6bd597c98b4d339b669b17210bf8c7",
      "value": 0
     }
    },
    "dbab8303ce4640e9aadb192fcafd5607": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbcd55d53d2f4ff7babe32283d13c008": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb53bccc684c4e9eb44877e8e6b5f9bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
